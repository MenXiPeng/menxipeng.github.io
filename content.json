{"meta":{"title":"门✈❣Bツ⊙g❦✈♂","subtitle":"mxp","description":"java;技术;博客;menxipeng","author":"mxp","url":"http://menxipeng.com","root":"/"},"pages":[{"title":"关于","date":"2020-07-30T04:15:46.552Z","updated":"2020-07-30T04:15:46.552Z","comments":true,"path":"about/index.html","permalink":"http://menxipeng.com/about/index.html","excerpt":"","text":"kkkkkk"},{"title":"红浪漫会员","date":"2020-07-31T06:50:41.948Z","updated":"2020-07-31T06:50:41.948Z","comments":true,"path":"friends/index.html","permalink":"http://menxipeng.com/friends/index.html","excerpt":"","text":""},{"title":"","date":"2020-07-30T02:45:46.337Z","updated":"2020-07-30T02:45:46.337Z","comments":true,"path":"messages/index.html","permalink":"http://menxipeng.com/messages/index.html","excerpt":"","text":""},{"title":"","date":"2020-07-31T02:01:11.955Z","updated":"2020-07-31T02:01:11.955Z","comments":true,"path":"references/index.html","permalink":"http://menxipeng.com/references/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2020-07-30T02:25:43.528Z","updated":"2020-07-30T02:25:43.528Z","comments":true,"path":"categories/index.html","permalink":"http://menxipeng.com/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2020-07-30T02:26:56.693Z","updated":"2020-07-30T02:26:56.693Z","comments":true,"path":"tags/index.html","permalink":"http://menxipeng.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Hadoop 3.x 单机安装","slug":"Hadoop","date":"2020-07-29T16:00:00.000Z","updated":"2020-07-31T01:59:26.542Z","comments":true,"path":"2020/07/30/Hadoop/","link":"","permalink":"http://menxipeng.com/2020/07/30/Hadoop/","excerpt":"关于hadoop 3.x 版本基础安装个人总结，建议以官网为指导进行配置，不同版本不一致，本教程适用于3.1.x官网地址：https://hadoop.apache.org/docs/current/","text":"关于hadoop 3.x 版本基础安装个人总结，建议以官网为指导进行配置，不同版本不一致，本教程适用于3.1.x官网地址：https://hadoop.apache.org/docs/current/ 一、下载hadoophttps://hadoop.apache.org/releases.html 二、解压hadoop包tar -zxvf hadoop-3.1.2.tar.gz 三、修改hosts文件1. vim /etc/hosts 2. 添加 0.0.0.0(内网ip) master master 3. source /etc/profile 四、生成ssh密钥1. ssh-keygen -t rsa -P &#39;&#39; # 第一个回车-输入要生成的文件名(默认id_rsa) # 第二个回车-输入生成密钥密码(默认为空) # 第三个回车-重复输入密码(默认为空) 2. cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys #master主机(互信密钥) # 不设置密钥互信会导致启动时出现权限不足的异常 五、配置hadoop Home1. vim /etc/profile 2. 添加 #hadoop enviroment hadoop环境变量 export HADOOP_HOME=/usr/local/hadoop-3.1.2/ #hadoop 根目录 export PATH=&quot;$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH&quot; export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop 3. source /etc/profile #重新加载源文件 六、修改hadoop 配置文件 $HADOOP_HOME # hadoop 根目录1234567891011121314151617$HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;hadoop-env.sh # 修改行 export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_112&#x2F;$HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;slaves (添加集群节点hostname,单机节点不需要修改)$HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;core-site.xml #添加如下内容：&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt; &lt;value&gt;hdfs:&#x2F;&#x2F;master:9000&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;&#x2F;name&gt; &lt;value&gt;131072&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt; &lt;value&gt;&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.2&#x2F;tmp&lt;&#x2F;value&gt; &lt;&#x2F;property&gt;&lt;&#x2F;configuration&gt; $HADOOP_HOME/etc/hadoop/hdfs-site.xml #添加如下内容12345678910111213141516171819202122232425262728293031&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;&#x2F;name&gt; &lt;value&gt;master:50090&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;&#x2F;name&gt; &lt;value&gt;1&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;&#x2F;name&gt; &lt;value&gt;file:&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.2&#x2F;hdfs&#x2F;name&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt; &lt;value&gt;file:&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.2&#x2F;hdfs&#x2F;data&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;&#x2F;name&gt; &lt;value&gt;false&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;dfs.client.block.write.replace-datanode-on-failure.enable&lt;&#x2F;name&gt; &lt;value&gt;true&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;dfs.client.block.write.replace-datanode-on-failure.policy&lt;&#x2F;name&gt; &lt;value&gt;NEVER&lt;&#x2F;value&gt; &lt;&#x2F;property&gt;&lt;&#x2F;configuration&gt; $HADOOP_HOME/etc/hadoop/mapred-site.xml(cp mapred-site.xml.template mapred-site.xml)123456789101112131415161718&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt; &lt;value&gt;yarn&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;&#x2F;name&gt; &lt;value&gt;master:10020&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;&#x2F;name&gt; &lt;value&gt;master:19888&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;!-- &lt;property&gt; &lt;name&gt;mapreduce.application.classpath&lt;&#x2F;name&gt; &lt;value&gt;$HADOOP_MAPRED_HOME&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;*:$HADOOP_MAPRED_HOME&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;*&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; --&gt;&lt;&#x2F;configuration&gt; $HADOOP_HOME/etc/hadoop/yarn-site.xml12345678910111213141516171819202122232425262728293031&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt; &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;&#x2F;name&gt; &lt;value&gt;master:8032&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;&#x2F;name&gt; &lt;value&gt;master:8030&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;&#x2F;name&gt; &lt;value&gt;master:8031&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;&#x2F;name&gt; &lt;value&gt;master:8033&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;&#x2F;name&gt; &lt;value&gt;master:8088&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; &lt;!-- &lt;property&gt; &lt;name&gt;yarn.nodemanager.env-whitelist&lt;&#x2F;name&gt; &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;&#x2F;value&gt; &lt;&#x2F;property&gt; --&gt;&lt;&#x2F;configuration&gt; 七、格式化namenode 节点 hadoop namenode -format 八、脚本配置1.启动 #!/bin/bash echo -e &quot;\\033[31m ========Start The Cluster======== \\033[0m&quot; echo -e &quot;\\033[31m Starting Hadoop Now !!! \\033[0m&quot; /opt/hadoop-2.7.3/sbin/start-all.sh echo -e &quot;\\033[31m Starting Spark Now !!! \\033[0m&quot; /opt/spark-2.1.0-bin-hadoop2.7/sbin/start-all.sh echo -e &quot;\\033[31m The Result Of The Command \\&quot;jps\\&quot; : \\033[0m&quot; jps echo -e &quot;\\033[31m ========END======== \\033[0m&quot; 2.停止脚本 #!/bin/bash echo -e &quot;\\033[31m ===== Stoping The Cluster ====== \\033[0m&quot; echo -e &quot;\\033[31m Stoping Spark Now !!! \\033[0m&quot; /opt/spark-2.1.0-bin-hadoop2.7/sbin/stop-all.sh echo -e &quot;\\033[31m Stopting Hadoop Now !!! \\033[0m&quot; /opt/hadoop-2.7.3/sbin/stop-all.sh echo -e &quot;\\033[31m The Result Of The Command \\&quot;jps\\&quot; : \\033[0m&quot; jps echo -e &quot;\\033[31m ======END======== \\033[0m&quot; 九、查看节点 jps----- Jps ----- DataNode ----- NameNode ----- NodeManager ----- SecondaryNameNode 看到所有节点代表启动成功 十、root启动报错start-dfs.sh / stop-dfs.sh HDFS_DATANODE_USER=root HADOOP_SECURE_DN_USER=hdfs HDFS_NAMENODE_USER=root HDFS_SECONDARYNAMENODE_USER=root start-yarn.sh / stop-yarn.sh YARN_RESOURCEMANAGER_USER=root HADOOP_SECURE_DN_USER=yarn YARN_NODEMANAGER_USER=root 参考 http://www.cnblogs.com/purstar/p/6293605.html","categories":[{"name":"大数据","slug":"大数据","permalink":"http://menxipeng.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hadoop搭建","slug":"大数据/Hadoop搭建","permalink":"http://menxipeng.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop%E6%90%AD%E5%BB%BA/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://menxipeng.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"Linux lsof命令","slug":"Liunx-lsof","date":"2020-07-29T16:00:00.000Z","updated":"2020-07-30T11:22:44.513Z","comments":true,"path":"2020/07/30/Liunx-lsof/","link":"","permalink":"http://menxipeng.com/2020/07/30/Liunx-lsof/","excerpt":"lsof命令可以列出被进程所打开的文件的信息。被打开的文件可以是 普通的文件， 目录","text":"lsof命令可以列出被进程所打开的文件的信息。被打开的文件可以是 普通的文件， 目录 网络文件系统的文件， 字符设备文件 (函数)共享库 管道，命名管道 符号链接 底层的socket字流，网络socket，unix域名socket在linux里面，大部分的东西都是被当做文件的…..还有其他很多 一、列出所有打开的文件lsof # 备注: 如果不加任何参数，就会打开所有被打开的文件，建议加上一下参数来具体定位 二、列出所有打开的文件lsof /filepath/file 三、递归查看某个目录的文件信息lsof +D /filepath/filepath2/ # 使用了+D，对应目录下的所有子目录和文件都会被列出 四、遍历查看某个目录的所有文件信息lsof | grep ‘/filepath/filepath2/’ 五、列出某个用户打开的文件信息lsof -u username 六、列出某个用户打开的文件信息lsof -c mysql # -c 选项将会列出所有以mysql开头的程序的文件，其实你也可以写成 lsof | grep mysql, 但是第一种方法明显比第二种方法要少打几个字符了 七、列出多个程序多打开的文件信息lsof -c mysql -c apache 八、列出某个用户以及某个程序所打开的文件信息lsof -u test -c mysql 九、列出除了某个用户外的被打开的文件信息lsof -u ^root #^这个符号在用户名之前，将会把是root用户打开的进程不让显示 十、通过某个进程号显示该进行打开的文件lsof -p 1 十一、列出多个进程号对应的文件信息lsof -p 123,456,789 十二、列出除了某个进程号，其他进程号所打开的文件信息lsof -p ^1 十三、网络连接lsof -i 十四、tcp 网络连接信息lsof -i tcp 十五、udp网络连接信息lsof -i udp 十六、使用端口信息lsof -i :3306 十七、使用udp端口信息lsof -i udp:55 十八、使用tcp端口信息lsof -i tcp:80 十九、用户的所有活跃的网络端口lsof -a -u test -i 二十、列出所有网络文件系统lsof -N 二十一、域名socket文件lsof -u 二十二、用户组所打开的文件信息lsof -g 5555 二十三、根据文件描述列出对应的文件信息lsof -d description(like 2) 二十四、文件描述范围列出文件信息lsof -d 2-3","categories":[{"name":"Linux","slug":"Linux","permalink":"http://menxipeng.com/categories/Linux/"},{"name":"lsof命令","slug":"Linux/lsof命令","permalink":"http://menxipeng.com/categories/Linux/lsof%E5%91%BD%E4%BB%A4/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://menxipeng.com/tags/Linux/"}]},{"title":"欢迎光临红浪漫","slug":"index","date":"2020-07-29T11:52:34.541Z","updated":"2020-07-30T08:49:23.006Z","comments":true,"path":"2020/07/29/index/","link":"","permalink":"http://menxipeng.com/2020/07/29/index/","excerpt":"","text":"男宾三位里边请～","categories":[],"tags":[]}],"categories":[{"name":"大数据","slug":"大数据","permalink":"http://menxipeng.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hadoop搭建","slug":"大数据/Hadoop搭建","permalink":"http://menxipeng.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop%E6%90%AD%E5%BB%BA/"},{"name":"Linux","slug":"Linux","permalink":"http://menxipeng.com/categories/Linux/"},{"name":"lsof命令","slug":"Linux/lsof命令","permalink":"http://menxipeng.com/categories/Linux/lsof%E5%91%BD%E4%BB%A4/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://menxipeng.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Linux","slug":"Linux","permalink":"http://menxipeng.com/tags/Linux/"}]}
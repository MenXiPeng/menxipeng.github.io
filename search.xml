<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Hadoop 3.x 单机安装</title>
      <link href="/2020/07/30/Hadoop/"/>
      <url>/2020/07/30/Hadoop/</url>
      
        <content type="html"><![CDATA[<p>关于hadoop 3.x 版本基础安装个人总结，建议以官网为指导进行配置，不同版本不一致，本教程适用于3.1.x<br>官网地址：<a href="https://hadoop.apache.org/docs/current/">https://hadoop.apache.org/docs/current/</a></p><a id="more"></a><h5 id="一、下载hadoop"><a href="#一、下载hadoop" class="headerlink" title="一、下载hadoop"></a>一、下载hadoop</h5><pre><code>https://hadoop.apache.org/releases.html</code></pre><h5 id="二、解压hadoop包"><a href="#二、解压hadoop包" class="headerlink" title="二、解压hadoop包"></a>二、解压hadoop包</h5><pre><code>tar -zxvf hadoop-3.1.2.tar.gz</code></pre><h5 id="三、修改hosts文件"><a href="#三、修改hosts文件" class="headerlink" title="三、修改hosts文件"></a>三、修改hosts文件</h5><pre><code>1. vim /etc/hosts  2. 添加 0.0.0.0(内网ip) master master 3. source /etc/profile</code></pre><h5 id="四、生成ssh密钥"><a href="#四、生成ssh密钥" class="headerlink" title="四、生成ssh密钥"></a>四、生成ssh密钥</h5><pre><code>1. ssh-keygen -t rsa -P &#39;&#39; # 第一个回车-输入要生成的文件名(默认id_rsa)# 第二个回车-输入生成密钥密码(默认为空)# 第三个回车-重复输入密码(默认为空)2. cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys #master主机(互信密钥)# 不设置密钥互信会导致启动时出现权限不足的异常</code></pre><h5 id="五、配置hadoop-Home"><a href="#五、配置hadoop-Home" class="headerlink" title="五、配置hadoop Home"></a>五、配置hadoop Home</h5><pre><code>1. vim /etc/profile 2. 添加 #hadoop enviroment hadoop环境变量export HADOOP_HOME=/usr/local/hadoop-3.1.2/ #hadoop 根目录export PATH=&quot;$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH&quot;export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoopexport YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop 3. source /etc/profile #重新加载源文件</code></pre><h5 id="六、修改hadoop-配置文件"><a href="#六、修改hadoop-配置文件" class="headerlink" title="六、修改hadoop 配置文件"></a>六、修改hadoop 配置文件</h5><ul><li>$HADOOP_HOME  # hadoop 根目录<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;hadoop-env.sh   # 修改行 export JAVA_HOME&#x3D;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_112&#x2F;</span><br><span class="line">$HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;slaves (添加集群节点hostname,单机节点不需要修改)</span><br><span class="line">$HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;core-site.xml   #添加如下内容：</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hdfs:&#x2F;&#x2F;master:9000&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">         &lt;name&gt;io.file.buffer.size&lt;&#x2F;name&gt;</span><br><span class="line">         &lt;value&gt;131072&lt;&#x2F;value&gt;</span><br><span class="line">       &lt;&#x2F;property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">                &lt;value&gt;&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.2&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">        &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure></li><li>$HADOOP_HOME/etc/hadoop/hdfs-site.xml #添加如下内容<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.namenode.secondary.http-address&lt;&#x2F;name&gt;</span><br><span class="line">      &lt;value&gt;master:50090&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">         &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.namenode.name.dir&lt;&#x2F;name&gt;</span><br><span class="line">      &lt;value&gt;file:&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.2&#x2F;hdfs&#x2F;name&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt;</span><br><span class="line">      &lt;value&gt;file:&#x2F;usr&#x2F;local&#x2F;hadoop-3.1.2&#x2F;hdfs&#x2F;data&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.permissions&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;false&lt;&#x2F;value&gt;</span><br><span class="line">     &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.client.block.write.replace-datanode-on-failure.enable&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;true&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.client.block.write.replace-datanode-on-failure.policy&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;NEVER&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure></li><li>$HADOOP_HOME/etc/hadoop/mapred-site.xml(cp mapred-site.xml.template mapred-site.xml)<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">      &lt;property&gt;</span><br><span class="line">          &lt;name&gt;mapreduce.jobhistory.address&lt;&#x2F;name&gt;</span><br><span class="line">          &lt;value&gt;master:10020&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">          &lt;name&gt;mapreduce.jobhistory.address&lt;&#x2F;name&gt;</span><br><span class="line">          &lt;value&gt;master:19888&lt;&#x2F;value&gt;</span><br><span class="line">  &lt;&#x2F;property&gt;</span><br><span class="line"> &lt;!--   &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.application.classpath&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;$HADOOP_MAPRED_HOME&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;*:$HADOOP_MAPRED_HOME&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;lib&#x2F;*&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt; --&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure></li><li>$HADOOP_HOME/etc/hadoop/yarn-site.xml<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">           &lt;name&gt;yarn.resourcemanager.address&lt;&#x2F;name&gt;</span><br><span class="line">           &lt;value&gt;master:8032&lt;&#x2F;value&gt;</span><br><span class="line">     &lt;&#x2F;property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">          &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;&#x2F;name&gt;</span><br><span class="line">          &lt;value&gt;master:8030&lt;&#x2F;value&gt;</span><br><span class="line">      &lt;&#x2F;property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">         &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;&#x2F;name&gt;</span><br><span class="line">         &lt;value&gt;master:8031&lt;&#x2F;value&gt;</span><br><span class="line">     &lt;&#x2F;property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">         &lt;name&gt;yarn.resourcemanager.admin.address&lt;&#x2F;name&gt;</span><br><span class="line">         &lt;value&gt;master:8033&lt;&#x2F;value&gt;</span><br><span class="line">     &lt;&#x2F;property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">         &lt;name&gt;yarn.resourcemanager.webapp.address&lt;&#x2F;name&gt;</span><br><span class="line">         &lt;value&gt;master:8088&lt;&#x2F;value&gt;</span><br><span class="line">         &lt;&#x2F;property&gt;</span><br><span class="line">   &lt;!-- &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt; --&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure><h5 id="七、格式化namenode-节点"><a href="#七、格式化namenode-节点" class="headerlink" title="七、格式化namenode 节点"></a>七、格式化namenode 节点</h5>  hadoop namenode -format</li></ul><h5 id="八、脚本配置"><a href="#八、脚本配置" class="headerlink" title="八、脚本配置"></a>八、脚本配置</h5><pre><code>1.启动#!/bin/bashecho -e &quot;\033[31m ========Start The Cluster======== \033[0m&quot;echo -e &quot;\033[31m Starting Hadoop Now !!! \033[0m&quot;/opt/hadoop-2.7.3/sbin/start-all.shecho -e &quot;\033[31m Starting Spark Now !!! \033[0m&quot;/opt/spark-2.1.0-bin-hadoop2.7/sbin/start-all.shecho -e &quot;\033[31m The Result Of The Command \&quot;jps\&quot; :  \033[0m&quot;jpsecho -e &quot;\033[31m ========END======== \033[0m&quot;2.停止脚本#!/bin/bashecho -e &quot;\033[31m ===== Stoping The Cluster ====== \033[0m&quot;echo -e &quot;\033[31m Stoping Spark Now !!! \033[0m&quot;/opt/spark-2.1.0-bin-hadoop2.7/sbin/stop-all.shecho -e &quot;\033[31m Stopting Hadoop Now !!! \033[0m&quot;/opt/hadoop-2.7.3/sbin/stop-all.shecho -e &quot;\033[31m The Result Of The Command \&quot;jps\&quot; :  \033[0m&quot;jpsecho -e &quot;\033[31m ======END======== \033[0m&quot;</code></pre><h5 id="九、查看节点-jps"><a href="#九、查看节点-jps" class="headerlink" title="九、查看节点 jps"></a>九、查看节点 jps</h5><pre><code>----- Jps----- DataNode----- NameNode----- NodeManager----- SecondaryNameNode看到所有节点代表启动成功</code></pre><h5 id="十、root启动报错"><a href="#十、root启动报错" class="headerlink" title="十、root启动报错"></a>十、root启动报错</h5><pre><code>start-dfs.sh / stop-dfs.shHDFS_DATANODE_USER=rootHADOOP_SECURE_DN_USER=hdfsHDFS_NAMENODE_USER=rootHDFS_SECONDARYNAMENODE_USER=rootstart-yarn.sh / stop-yarn.shYARN_RESOURCEMANAGER_USER=rootHADOOP_SECURE_DN_USER=yarnYARN_NODEMANAGER_USER=root参考 http://www.cnblogs.com/purstar/p/6293605.html</code></pre>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
          <category> Hadoop搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux lsof命令</title>
      <link href="/2020/07/30/Liunx-lsof/"/>
      <url>/2020/07/30/Liunx-lsof/</url>
      
        <content type="html"><![CDATA[<p>lsof命令可以列出被进程所打开的文件的信息。被打开的文件可以是</p><ul><li>普通的文件，</li><li>目录  <a id="more"></a></li><li>网络文件系统的文件，</li><li>字符设备文件  </li><li>(函数)共享库  </li><li>管道，命名管道 </li><li>符号链接</li><li>底层的socket字流，网络socket，unix域名socket<br>在linux里面，大部分的东西都是被当做文件的…..还有其他很多</li></ul><hr><h6 id="一、列出所有打开的文件"><a href="#一、列出所有打开的文件" class="headerlink" title="一、列出所有打开的文件"></a>一、列出所有打开的文件</h6><pre><code>lsof # 备注: 如果不加任何参数，就会打开所有被打开的文件，建议加上一下参数来具体定位</code></pre><h6 id="二、列出所有打开的文件"><a href="#二、列出所有打开的文件" class="headerlink" title="二、列出所有打开的文件"></a>二、列出所有打开的文件</h6><pre><code>lsof   /filepath/file </code></pre><h5 id="三、递归查看某个目录的文件信息"><a href="#三、递归查看某个目录的文件信息" class="headerlink" title="三、递归查看某个目录的文件信息"></a>三、递归查看某个目录的文件信息</h5><pre><code>lsof +D /filepath/filepath2/ # 使用了+D，对应目录下的所有子目录和文件都会被列出</code></pre><h5 id="四、遍历查看某个目录的所有文件信息"><a href="#四、遍历查看某个目录的所有文件信息" class="headerlink" title="四、遍历查看某个目录的所有文件信息"></a>四、遍历查看某个目录的所有文件信息</h5><pre><code>lsof | grep ‘/filepath/filepath2/’</code></pre><h5 id="五、列出某个用户打开的文件信息"><a href="#五、列出某个用户打开的文件信息" class="headerlink" title="五、列出某个用户打开的文件信息"></a>五、列出某个用户打开的文件信息</h5><pre><code>lsof  -u username</code></pre><h5 id="六、列出某个用户打开的文件信息"><a href="#六、列出某个用户打开的文件信息" class="headerlink" title="六、列出某个用户打开的文件信息"></a>六、列出某个用户打开的文件信息</h5><pre><code>lsof -c mysql # -c 选项将会列出所有以mysql开头的程序的文件，其实你也可以写成 lsof | grep mysql, 但是第一种方法明显比第二种方法要少打几个字符了</code></pre><h5 id="七、列出多个程序多打开的文件信息"><a href="#七、列出多个程序多打开的文件信息" class="headerlink" title="七、列出多个程序多打开的文件信息"></a>七、列出多个程序多打开的文件信息</h5><pre><code>lsof -c mysql -c apache</code></pre><h5 id="八、列出某个用户以及某个程序所打开的文件信息"><a href="#八、列出某个用户以及某个程序所打开的文件信息" class="headerlink" title="八、列出某个用户以及某个程序所打开的文件信息"></a>八、列出某个用户以及某个程序所打开的文件信息</h5><pre><code>lsof -u test -c mysql</code></pre><h5 id="九、列出除了某个用户外的被打开的文件信息"><a href="#九、列出除了某个用户外的被打开的文件信息" class="headerlink" title="九、列出除了某个用户外的被打开的文件信息"></a>九、列出除了某个用户外的被打开的文件信息</h5><pre><code>lsof   -u ^root #^这个符号在用户名之前，将会把是root用户打开的进程不让显示</code></pre><h5 id="十、通过某个进程号显示该进行打开的文件"><a href="#十、通过某个进程号显示该进行打开的文件" class="headerlink" title="十、通过某个进程号显示该进行打开的文件"></a>十、通过某个进程号显示该进行打开的文件</h5><pre><code>lsof -p 1</code></pre><h5 id="十一、列出多个进程号对应的文件信息"><a href="#十一、列出多个进程号对应的文件信息" class="headerlink" title="十一、列出多个进程号对应的文件信息"></a>十一、列出多个进程号对应的文件信息</h5><pre><code>lsof -p 123,456,789</code></pre><h5 id="十二、列出除了某个进程号，其他进程号所打开的文件信息"><a href="#十二、列出除了某个进程号，其他进程号所打开的文件信息" class="headerlink" title="十二、列出除了某个进程号，其他进程号所打开的文件信息"></a>十二、列出除了某个进程号，其他进程号所打开的文件信息</h5><pre><code>lsof -p ^1</code></pre><h5 id="十三、网络连接"><a href="#十三、网络连接" class="headerlink" title="十三、网络连接"></a>十三、网络连接</h5><pre><code>lsof -i</code></pre><h5 id="十四、tcp-网络连接信息"><a href="#十四、tcp-网络连接信息" class="headerlink" title="十四、tcp 网络连接信息"></a>十四、tcp 网络连接信息</h5><pre><code>lsof  -i tcp</code></pre><h5 id="十五、udp网络连接信息"><a href="#十五、udp网络连接信息" class="headerlink" title="十五、udp网络连接信息"></a>十五、udp网络连接信息</h5><pre><code>lsof  -i udp</code></pre><h5 id="十六、使用端口信息"><a href="#十六、使用端口信息" class="headerlink" title="十六、使用端口信息"></a>十六、使用端口信息</h5><pre><code>lsof -i :3306</code></pre><h5 id="十七、使用udp端口信息"><a href="#十七、使用udp端口信息" class="headerlink" title="十七、使用udp端口信息"></a>十七、使用udp端口信息</h5><pre><code>lsof -i udp:55</code></pre><h5 id="十八、使用tcp端口信息"><a href="#十八、使用tcp端口信息" class="headerlink" title="十八、使用tcp端口信息"></a>十八、使用tcp端口信息</h5><pre><code>lsof -i tcp:80</code></pre><h5 id="十九、用户的所有活跃的网络端口"><a href="#十九、用户的所有活跃的网络端口" class="headerlink" title="十九、用户的所有活跃的网络端口"></a>十九、用户的所有活跃的网络端口</h5><pre><code>lsof  -a -u test -i</code></pre><h5 id="二十、列出所有网络文件系统"><a href="#二十、列出所有网络文件系统" class="headerlink" title="二十、列出所有网络文件系统"></a>二十、列出所有网络文件系统</h5><pre><code>lsof -N</code></pre><h5 id="二十一、域名socket文件"><a href="#二十一、域名socket文件" class="headerlink" title="二十一、域名socket文件"></a>二十一、域名socket文件</h5><pre><code>lsof -u</code></pre><h5 id="二十二、用户组所打开的文件信息"><a href="#二十二、用户组所打开的文件信息" class="headerlink" title="二十二、用户组所打开的文件信息"></a>二十二、用户组所打开的文件信息</h5><pre><code>lsof -g 5555</code></pre><h5 id="二十三、根据文件描述列出对应的文件信息"><a href="#二十三、根据文件描述列出对应的文件信息" class="headerlink" title="二十三、根据文件描述列出对应的文件信息"></a>二十三、根据文件描述列出对应的文件信息</h5><pre><code>lsof -d description(like 2)</code></pre><h5 id="二十四、文件描述范围列出文件信息"><a href="#二十四、文件描述范围列出文件信息" class="headerlink" title="二十四、文件描述范围列出文件信息"></a>二十四、文件描述范围列出文件信息</h5><pre><code>lsof -d 2-3</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> lsof命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>欢迎光临红浪漫</title>
      <link href="/2020/07/29/index/"/>
      <url>/2020/07/29/index/</url>
      
        <content type="html"><![CDATA[<p>男宾三位里边请～</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
